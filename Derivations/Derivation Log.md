September 22, 2025

Status: Active

Tags: #Derivations #Math #Proofs

# Derivation Log

Purpose: Central place to consolidate completed derivations, gradient calculations, decompositions, and proof sketches to reduce re-learning friction.

## Format Template
```
### Title
Domain: (Linear Algebra / Probability / Optimization / Information / Misc)
Source Trigger: (Which note / paper / problem?)
Goal: (What are we proving / deriving?)
Assumptions:
- ...
Derivation Steps (succinct numbered):
1.
2.
3.
Result:
Sanity Check:
- Numerical example / dimension check / limiting behavior
Applications:
- Where used (link to notes)
Reflections / Pitfalls:
- ...
```

## Index
| Date | Title | Domain | Linked Usage | Confidence (1–5) |
|------|-------|--------|--------------|------------------|

## Backlog (Planned Derivations)
- PCA variance maximization → eigenvectors
- Logistic regression gradient
- Softmax + cross-entropy stable form
- Bias–variance decomposition
- Entropy & KL for Bernoulli edge cases
- L1 vs L2 geometry intuition sketch
- Variance decomposition Var(Y) = E[Var(Y|X)] + Var(E[Y|X])

## Cross Links
- Core math roadmap: [[../9. To Learn/Math for DS]]
- Modeling applications: [[../9. To Learn/Data Science]]
- Performance considerations (vectorization): [[../9. To Learn/C++]]

---
Keep entries concise; optimize for future recall speed over completeness.
